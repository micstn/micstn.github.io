{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training word2vec model from CVs texts with gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gc\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mstaniszewsk/anaconda3/lib/python3.6/site-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.22) or chardet (2.3.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "/Users/mstaniszewsk/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/mstaniszewsk/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_documents\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import *\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "import mypykit as mpk\n",
    "\n",
    "gc.collect()\n",
    "csv.field_size_limit(sys.maxsize) # some of the text fields can be very big..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### GET TEXTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#texts_stream = mpk.generator_csv2text(\"../data/sample_candidates_texts.csv\", text_column_index=text_col)\n",
    "\n",
    "filepath = \"../data/sample_candidates_texts.csv\"\n",
    "text_col = 1\n",
    "custom_filters = [lambda x: x.lower(),\n",
    "                  strip_tags,\n",
    "                  strip_punctuation,\n",
    "                  strip_multiple_whitespaces]\n",
    "\n",
    "#Word2Vec needs to iterate many times over documents so it does not accept the generator :/ Use CSVIterator\n",
    "texts_stream = mpk.CSVIterator(filepath, custom_filters, col_index=text_col, cut_char=5000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### PREPROCESING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#texts = [preprocess_string(filters=custom_filters, s=text) for text in texts_stream]\n",
    "texts = [t for t in texts_stream]\n",
    "print(\"Number of documents in the stream:\", len(texts))\n",
    "print(\"texts object size:\", sys.getsizeof(texts)/1e+6, 'megabytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mpk.write_txt(\"../data/sample_tokenized_texts.txt\", texts_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dictionary = corpora.Dictionary(texts_stream)\n",
    "dictionary.save('../models/samlple_cvs_dict_lvl_1.dict')\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN WORD2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "class Txts2Lists:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "\n",
    "    def __iter__(self):\n",
    "        with open(self.path, \"r\") as f:\n",
    "            for line in f:\n",
    "                if len(line) > 2:\n",
    "                    yield ast.literal_eval(line)\n",
    "                    #yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Word2Vec needs to iterate many times over documents so it does not accept the generator :/ Use iterable\n",
    "texts_stream = Txts2Lists(\"../data/all_tokenized_texts.txt\")\n",
    "model = Word2Vec(texts_stream, size=100, window=5, min_count=10, workers=4, iter=5)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"../models/cvs_w2v_lvl_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = mpk.w2v_embedding_matrix(model, vector_dim=100)\n",
    "weights = embedding_matrix\n",
    "with open('../data/cvs_w2v_weights_lvl_1.pickle', 'wb') as handle:\n",
    "    pickle.dump(weights, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save embeddings with vocab to csv for R EDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../data/embeddings_lvl3.csv', weights, delimiter=',')   \n",
    "vocab = [word for word, vocab_obj in model.wv.vocab.items()]\n",
    "df_vocab = pd.DataFrame({\"token\": vocab})\n",
    "df_vocab.to_csv(\"../data/vocab_lvl3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"../models/cvs_w2v_lvl_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('invasion', 0.7615526914596558),\n",
       " ('cold_war', 0.7589760422706604),\n",
       " ('wars', 0.7434630393981934),\n",
       " ('terror', 0.7399106621742249),\n",
       " ('civil_war', 0.7309882640838623),\n",
       " ('protest', 0.7121016979217529),\n",
       " ('arab_spring', 0.7008945345878601),\n",
       " ('riots', 0.6994553804397583),\n",
       " ('genocide', 0.6945540308952332),\n",
       " ('bombing', 0.6943058967590332)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['war'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tokyo', 0.8857423067092896),\n",
       " ('taipei', 0.780282199382782),\n",
       " ('seoul', 0.7592018842697144),\n",
       " ('beijing', 0.7475929260253906),\n",
       " ('fukuoka', 0.7475562691688538),\n",
       " ('osaka', 0.7459617853164673),\n",
       " ('hong_kong', 0.7339567542076111),\n",
       " ('japan_tokyo', 0.7339449524879456),\n",
       " ('tokyo_japan', 0.7141210436820984),\n",
       " ('taiwan', 0.7088636159896851)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[\"japan\", \"paris\"], negative=[\"france\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding bigrams with phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "texts_stream = Txts2Lists(\"../data/all_tokenized_texts.txt\")\n",
    "phrases = Phrases(texts_stream, min_count=10)\n",
    "bigram_transformer = Phraser(phrases)\n",
    "mpk.write_txt(\"../data/all_tokenized_texts_lvl2.txt\", bigram_transformer[texts_stream])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict2 = corpora.Dictionary(bigram_transformer[texts_stream])\n",
    "dict2.save('../models/cvs_dict_lvl_2.dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding trigrams with phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "texts_stream = Txts2Lists(\"../data/all_tokenized_texts_lvl2.txt\")\n",
    "phrases = Phrases(texts_stream, min_count=10)\n",
    "bigram_transformer = Phraser(phrases)\n",
    "mpk.write_txt(\"../data/all_tokenized_texts_lvl3.txt\", bigram_transformer[texts_stream])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict3 = corpora.Dictionary(bigram_transformer[texts_stream])\n",
    "dict3.save('../models/cvs_dict_lvl_3.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpk.save_pickle(\"../data/trigram_phrases\", phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrain Word2Vec including ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"../models/cvs_w2v_lvl_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Updating W2V model with phrases - level 2...\")\n",
    "texts_stream = Txts2Lists(\"../data/all_tokenized_texts_lvl2.txt\")\n",
    "model.build_vocab(texts_stream, update=True)\n",
    "model.train(texts_stream, total_examples=model.corpus_count, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/cvs_w2v_lvl_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Updating W2V model with phrases - level 3...\")\n",
    "texts_stream = Txts2Lists(\"../data/all_tokenized_texts_lvl3.txt\")\n",
    "model.build_vocab(texts_stream, update=True)\n",
    "model.train(texts_stream, total_examples=model.corpus_count, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/cvs_w2v_lvl_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = model_lvl_3.wv.get_keras_embedding() !!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### EXPLORE VECTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_algebra(positive=[], negative=[], n=1):\n",
    "    if len(negative) < 1:\n",
    "        return model.wv.most_similar(positive=positive, negative=negative, topn=n)\n",
    "    else:\n",
    "        return model.wv.most_similar(positive=positive, topn=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity('good', 'great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity('good', 'bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7531644973978595"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('python', 'perl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4378327513749595"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('python', 'excel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('facebook', 0.7660043835639954),\n",
       " ('twitter', 0.7028908133506775),\n",
       " ('instagram', 0.6729579567909241),\n",
       " ('sns', 0.6694015860557556),\n",
       " ('fb_twitter', 0.6657751798629761),\n",
       " ('utm_source', 0.6575230956077576),\n",
       " ('facebok', 0.6562955975532532),\n",
       " ('facbook', 0.6500971913337708),\n",
       " ('facebook_twitter_foursquare', 0.6500629186630249),\n",
       " ('facebook_twitter_youtube', 0.6386256814002991)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['fb'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bigdata', 0.6311461329460144),\n",
       " ('next_gen', 0.6159036159515381),\n",
       " ('saas_paas_iaas', 0.6142393946647644),\n",
       " ('paas_iaas', 0.609619677066803),\n",
       " ('predix', 0.607494592666626),\n",
       " ('cloud_iaas', 0.601280927658081),\n",
       " ('devops', 0.6005290746688843),\n",
       " ('nutanix', 0.5990670323371887),\n",
       " ('thoughtworks', 0.5987235903739929),\n",
       " ('ibm_bluemix', 0.5975252985954285)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['big_data'], negative=['statistics'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('frontend', 0.4715600311756134)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['back_end'], negative=['server'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive = ['china'], topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive = ['japan', 'berlin'], negative = ['germany'], topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('baidu', 0.7313236594200134)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive = ['google', 'china'], topn = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('database', 0.6572868227958679)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive = ['excel', 'network'], topn = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('formulas_vlookups', 0.5358480215072632)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive = ['excel'], negative=['server'], topn = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('word', 0.7538812756538391)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive = ['excel', 'text'], topn = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('macros', 0.713035523891449)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive = ['excel', 'code'], topn = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('google_sheets', 0.8080769181251526)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive = ['excel', 'google'], topn = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive = ['big_data', 'server'], topn = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('matlab', 0.8165830373764038)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive = ['spss', 'programming'], topn = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive = ['spss'], negative=['statistics'], topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive = ['python'], negative=['statistics'], topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('strength', 0.5720359683036804),\n",
       " ('happiness', 0.5691606402397156),\n",
       " ('successful', 0.5664874911308289),\n",
       " ('driving_force', 0.553283154964447),\n",
       " ('goal', 0.543483555316925),\n",
       " ('grit', 0.5434126853942871),\n",
       " ('succes', 0.5314896106719971),\n",
       " ('greatness', 0.5310738682746887),\n",
       " ('feeling', 0.5299428701400757),\n",
       " ('woman', 0.5228298902511597)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive = ['man', 'success'], topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('happiness', 0.6242830753326416),\n",
       " ('feeling', 0.6065638661384583),\n",
       " ('ambition', 0.6007509231567383),\n",
       " ('life', 0.5921899676322937),\n",
       " ('entrepreneurial_spirit', 0.5919184684753418),\n",
       " ('heart', 0.58869868516922),\n",
       " ('driving_force', 0.5848144292831421),\n",
       " ('growth', 0.5792322158813477),\n",
       " ('goal', 0.5706526637077332),\n",
       " ('challenge', 0.5669323801994324)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive = ['woman', 'success'], topn = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPLORE WITH TENSORBOARD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/50492676/visualize-gensim-word2vec-embeddings-in-tensorboard-projector/50499090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb = tf.Variable(embedding_matrix, name='word_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    save_path = saver.save(sess, \"../model_dir/model.ckpt\")\n",
    "    print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_lvl_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = '\\n'.join(list(model.wv.vocab.keys()))\n",
    "\n",
    "with open(os.path.join('../model_dir', 'metadata.tsv'), 'w') as f:\n",
    "   f.write(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir ../model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
